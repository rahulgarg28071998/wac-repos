{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Users/rahulgarg/opt/anaconda3/lib/python3.7/site-packages (0.5.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Users/rahulgarg/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üò†\n"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize(\":angry_face:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_emoji.csv\" , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    0:\":beating_heart:\",\n",
    "    1:\":baseball:\",\n",
    "    2:\":beaming_face_with_smiling_eyes:\",\n",
    "    3:\":disappointed_face:\",\n",
    "    4:\":fork_and_knife:\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíì\n",
      "‚öæ\n",
      "üòÅ\n",
      "üòû\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in emoji_dict.values():\n",
    "    print(emoji.emojize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[0]\n",
    "Y_train = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'proud', 'of', 'your', 'achievements']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulgarg/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[0]):\n",
    "    X_train[i] = X_train[i].lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [never, talk, to, me, again]\n",
       "1       [i, am, proud, of, your, achievements]\n",
       "2      [it, is, the, worst, day, in, my, life]\n",
       "3                        [miss, you, so, much]\n",
       "4                             [food, is, life]\n",
       "                        ...                   \n",
       "127          [he, had, to, make, a, home, run]\n",
       "128                    [i, am, ordering, food]\n",
       "129               [what, is, wrong, with, you]\n",
       "130                             [i, love, you]\n",
       "131                               [great, job]\n",
       "Name: 0, Length: 132, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r',encoding='utf8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string =  \"the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.092086,  0.2571  , -0.58693 , -0.37029 ,  1.0828  , -0.55466 ,\n",
       "       -0.78142 ,  0.58696 , -0.58714 ,  0.46318 , -0.11267 ,  0.2606  ,\n",
       "       -0.26928 , -0.072466,  1.247   ,  0.30571 ,  0.56731 ,  0.30509 ,\n",
       "       -0.050312, -0.64443 , -0.54513 ,  0.86429 ,  0.20914 ,  0.56334 ,\n",
       "        1.1228  , -1.0516  , -0.78105 ,  0.29656 ,  0.7261  , -0.61392 ,\n",
       "        2.4225  ,  1.0142  , -0.17753 ,  0.4147  , -0.12966 , -0.47064 ,\n",
       "        0.3807  ,  0.16309 , -0.323   , -0.77899 , -0.42473 , -0.30826 ,\n",
       "       -0.42242 ,  0.055069,  0.38267 ,  0.037415, -0.4302  , -0.39442 ,\n",
       "        0.10511 ,  0.87286 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(words):\n",
    "    ans = word_to_vec_map[words[0]]\n",
    "    for i in range(1,len(words)):\n",
    "        ans = np.add(ans,word_to_vec_map[words[i]])\n",
    "    ans = ans / float(len(words))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n",
      "[ 9.718460e-02  1.743740e-02  5.284300e-02 -4.368060e-01  2.756132e-01\n",
      " -1.426688e-01 -6.120520e-01  4.716140e-01 -6.059740e-01  1.566594e-01\n",
      " -8.662400e-02  4.906620e-01 -6.480320e-01 -1.612960e-01  8.897200e-01\n",
      "  4.867520e-01  4.601260e-02 -8.363342e-02 -2.288840e-01 -4.151500e-01\n",
      " -1.140000e-02  6.407600e-01  5.954280e-01  1.780868e-01  7.128668e-01\n",
      " -2.072760e+00 -3.161338e-01  1.869920e-01  6.583040e-01 -6.969300e-01\n",
      "  3.172380e+00  5.411100e-01 -5.941440e-01 -3.028740e-01 -2.285386e-01\n",
      " -2.899120e-01  2.006040e-01  1.053064e-01 -3.933000e-02 -4.483020e-01\n",
      " -1.353596e-01 -2.031200e-03 -2.454976e-01  1.305460e-01 -1.976000e-02\n",
      "  2.025340e-02 -1.199070e-01 -2.522034e-01 -2.197784e-01  3.076060e-01]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(avg_word(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numbers = np.zeros((X_train.shape[0],50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_train.shape[0]):\n",
    "    X_numbers[i] = avg_word(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_numbers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10,activation=\"relu\",input_shape=(50,)))\n",
    "model.add(Dense(5,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 565\n",
      "Trainable params: 565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_onehot = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss = \"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 869us/step - loss: 1.6484 - accuracy: 0.3030\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 256us/step - loss: 1.6228 - accuracy: 0.3182\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 118us/step - loss: 1.6032 - accuracy: 0.3258\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 1.5860 - accuracy: 0.3409\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 123us/step - loss: 1.5707 - accuracy: 0.3561\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 154us/step - loss: 1.5581 - accuracy: 0.3561\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 197us/step - loss: 1.5446 - accuracy: 0.3561\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 194us/step - loss: 1.5323 - accuracy: 0.3636\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 118us/step - loss: 1.5215 - accuracy: 0.4015\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 124us/step - loss: 1.5109 - accuracy: 0.4242\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 168us/step - loss: 1.5008 - accuracy: 0.4318\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 202us/step - loss: 1.4907 - accuracy: 0.4242\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 192us/step - loss: 1.4803 - accuracy: 0.4394\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 251us/step - loss: 1.4707 - accuracy: 0.4394\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 1.4607 - accuracy: 0.4470\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 129us/step - loss: 1.4509 - accuracy: 0.4545\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 192us/step - loss: 1.4411 - accuracy: 0.4545\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 210us/step - loss: 1.4298 - accuracy: 0.4621\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 191us/step - loss: 1.4200 - accuracy: 0.4697\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 178us/step - loss: 1.4106 - accuracy: 0.4621\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 1.4015 - accuracy: 0.4697\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 108us/step - loss: 1.3932 - accuracy: 0.4848\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.3835 - accuracy: 0.4924\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 103us/step - loss: 1.3743 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 163us/step - loss: 1.3648 - accuracy: 0.4848\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 146us/step - loss: 1.3546 - accuracy: 0.5152\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 1.3442 - accuracy: 0.5303\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 1.3334 - accuracy: 0.5379\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 124us/step - loss: 1.3218 - accuracy: 0.5530\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 1.3100 - accuracy: 0.5455\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 107us/step - loss: 1.3004 - accuracy: 0.5379\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 126us/step - loss: 1.2901 - accuracy: 0.5606\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 142us/step - loss: 1.2793 - accuracy: 0.5606\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 168us/step - loss: 1.2690 - accuracy: 0.5758\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 263us/step - loss: 1.2580 - accuracy: 0.5833\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 235us/step - loss: 1.2477 - accuracy: 0.5909\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 1.2382 - accuracy: 0.5758\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 143us/step - loss: 1.2289 - accuracy: 0.5758\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 112us/step - loss: 1.2194 - accuracy: 0.5833\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 137us/step - loss: 1.2096 - accuracy: 0.5909\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 141us/step - loss: 1.1981 - accuracy: 0.5909\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 216us/step - loss: 1.1879 - accuracy: 0.5985\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 152us/step - loss: 1.1780 - accuracy: 0.6212\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 119us/step - loss: 1.1676 - accuracy: 0.6212\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.1578 - accuracy: 0.6136\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 122us/step - loss: 1.1489 - accuracy: 0.6136\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.1394 - accuracy: 0.6288\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 121us/step - loss: 1.1301 - accuracy: 0.6439\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.1212 - accuracy: 0.6364\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 150us/step - loss: 1.1118 - accuracy: 0.6288\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 103us/step - loss: 1.1027 - accuracy: 0.6439\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 184us/step - loss: 1.0939 - accuracy: 0.6439\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 108us/step - loss: 1.0851 - accuracy: 0.6364\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 123us/step - loss: 1.0756 - accuracy: 0.6515\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 1.0673 - accuracy: 0.6439\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 1.0590 - accuracy: 0.6364\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 1.0497 - accuracy: 0.6364\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 137us/step - loss: 1.0422 - accuracy: 0.6439\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 186us/step - loss: 1.0358 - accuracy: 0.6515\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 106us/step - loss: 1.0282 - accuracy: 0.6364\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 135us/step - loss: 1.0190 - accuracy: 0.6439\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 1.0106 - accuracy: 0.6515\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 1.0029 - accuracy: 0.6591\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 254us/step - loss: 0.9967 - accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 226us/step - loss: 0.9894 - accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 148us/step - loss: 0.9832 - accuracy: 0.6742\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 132us/step - loss: 0.9757 - accuracy: 0.6818\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 0.9684 - accuracy: 0.6742\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 0.9616 - accuracy: 0.6742\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 197us/step - loss: 0.9550 - accuracy: 0.6894\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.9467 - accuracy: 0.6818\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 260us/step - loss: 0.9394 - accuracy: 0.6742\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 150us/step - loss: 0.9320 - accuracy: 0.6818\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 175us/step - loss: 0.9266 - accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.9196 - accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 0.9131 - accuracy: 0.6742\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 113us/step - loss: 0.9069 - accuracy: 0.6818\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 146us/step - loss: 0.9005 - accuracy: 0.6894\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 264us/step - loss: 0.8947 - accuracy: 0.7121\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 142us/step - loss: 0.8884 - accuracy: 0.7045\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 122us/step - loss: 0.8833 - accuracy: 0.7045\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 80us/step - loss: 0.8765 - accuracy: 0.7045\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 106us/step - loss: 0.8713 - accuracy: 0.6970\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 0.8655 - accuracy: 0.7045\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 182us/step - loss: 0.8605 - accuracy: 0.7121\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 105us/step - loss: 0.8551 - accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 124us/step - loss: 0.8486 - accuracy: 0.7424\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 163us/step - loss: 0.8461 - accuracy: 0.7348\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 177us/step - loss: 0.8419 - accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 143us/step - loss: 0.8368 - accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.8309 - accuracy: 0.7197\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 0.8254 - accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 131us/step - loss: 0.8213 - accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 119us/step - loss: 0.8161 - accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 119us/step - loss: 0.8109 - accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 138us/step - loss: 0.8043 - accuracy: 0.7197\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 106us/step - loss: 0.7998 - accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 121us/step - loss: 0.7977 - accuracy: 0.7348\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 155us/step - loss: 0.7943 - accuracy: 0.7348\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 90us/step - loss: 0.7886 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63debacd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_numbers,Y_train_onehot,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
